description: data2vec_jt_finetune

target:
  name: msrresrchvc
  service: aisc

environment:
  # image: zhyyao/fairseq_amlt_torch1.8:torch1.11
  # image: lozhou/fairseq_aml_docker:torch1.8_fairseq
  # image: wumark/speech_transducer:a100_fairseq_kenlm # decoding
  # image: sanyuanchen/data2vec:torch1.8 # no_c10d, without cudnn
  image: zym22/data2vec:torch1.8 # fork from sanyuanchen/data2vec:torch1.8
  # image: wumark/speech_transducer:torch1.6_wav2vec # past
  # image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel
  # registry: docker.io # any public registry can be specified here
  setup:
    # - pwd
    # - sudo `which pip` install bitarray
    # - sudo `which pip` install kaldiio
    # - sudo `which pip` install numpy==1.22.0
    # - sudo `which pip` install sacrebleu==1.5.1
    # - sudo `which pip` install sacrebleu[ja]
    # - sudo `which pip` install tensorboardX
    # - sudo `which pip` install tensorboard
    # - sudo `which pip` install editdistance
    # - sudo `which pip` install azureml-defaults
    # - sudo `which pip` install --editable ./
    - pip install --editable ./
    # - python setup.py build_ext --inplace
    #   - ./submit_script/ITP_bash_scripts/data2vec/install.sh

storage:
  data_blob:
    storage_account_name: tsprmblob01scus
    container_name: data
    mount_dir: /datablob
  model_blob:
    storage_account_name: tsstd01scus
    container_name: models
    mount_dir: /modelblob

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ~/github/fairseq/

search:
  job_template:
    name: data2vec_jt_960h_960h_6text_6share_1add_0kstart_001ctc_finetune_2x16G4-P100-IB
    sku: NCv2:2x16G4-P100-IB
    mpi: True
    process_count_per_node: 4
    priority: high
    sla_tier: premium # premium, standard, basic
    command:
    - realpath .
    # - bash submit_script/debug/hold_sleep.sh
    # - bash submit_script/debug/debug.sh
    # - bash data2vec_jt/script/submit_pretrain.sh {ctc_start_step} {ctc_end_step} {ctc_loss_alpha}
    - bash data2vec_jt/script/submit_finetune.sh
    - sleep infinity
    # submit_args:
    #   env:
    #     SHARED_MEMORY_PERCENT: 0.5
  type: grid
  max_trials: 16
  # params:
  #   - name: ctc_start_step
  #     values: [0, 100000]
  #   - name: ctc_end_step
  #     values: [200000, 400000]
  #   - name: ctc_loss_alpha
  #     values: [1, 10]
